{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuaUXUm4-W_3"
      },
      "source": [
        "# **Mount the Google drive**\n",
        "The trained models are uploaded to the google drive and inorder to load them the drive is mounted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU4X3QNMuvwc",
        "outputId": "2e3a2022-3a7d-4851-de08-ebbf915b4d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euNmXHWKgo2F",
        "outputId": "ee1a692b-d253-43dc-f632-c4f5c12dfa66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detection-of-motorcyclists-without-helmet'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 46 (delta 0), reused 43 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (46/46), 29.49 MiB | 37.37 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 860.43 MiB | 83.32 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/manikanta-varaganti/detection-of-motorcyclists-without-helmet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvuncz1Au4HI",
        "outputId": "c6254c03-7a08-43cc-ea81-60e6133b4515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/detection-of-motorcyclists-without-helmet/HelmetDetection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/detection-of-motorcyclists-without-helmet/HelmetDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "595wggyR-nno"
      },
      "source": [
        "# **Import the required packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F0ljq2CuoiL",
        "outputId": "6ea07ae7-f54b-4082-ba0f-6cc1be7e2b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 96720, done.\u001b[K\n",
            "remote: Total 96720 (delta 0), reused 0 (delta 0), pack-reused 96720\u001b[K\n",
            "Receiving objects: 100% (96720/96720), 610.81 MiB | 41.71 MiB/s, done.\n",
            "Resolving deltas: 100% (70418/70418), done.\n"
          ]
        }
      ],
      "source": [
        "# clone Tensorflow object detection api\n",
        "!git clone https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGhZgUMVwR59",
        "outputId": "339ca447-ca1e-4d3e-b43d-cba51b7329d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r            \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [773 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,356 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,898 kB]\n",
            "Fetched 4,261 kB in 2s (2,293 kB/s)\n",
            "Reading package lists... Done\n",
            "E: Unable to locate package python-pil\n",
            "E: Unable to locate package python-lxml\n"
          ]
        }
      ],
      "source": [
        "# Run to install proto buffers for object detection api\n",
        "!apt-get update\n",
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZHcMTEVhW_2",
        "outputId": "c9a47552-4e8c-4a55-dd4c-4207b82c3d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting inference-sdk\n",
            "  Downloading inference_sdk-0.9.17-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from inference-sdk) (2.31.0)\n",
            "Collecting dataclasses-json>=0.6.0 (from inference-sdk)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: opencv-python>=4.8.0.0 in /usr/local/lib/python3.10/dist-packages (from inference-sdk) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from inference-sdk) (9.4.0)\n",
            "Collecting supervision<1.0.0 (from inference-sdk)\n",
            "  Downloading supervision-0.19.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from inference-sdk) (1.25.2)\n",
            "Requirement already satisfied: aiohttp>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from inference-sdk) (3.9.3)\n",
            "Collecting backoff>=2.2.0 (from inference-sdk)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting aioresponses>=0.7.6 (from inference-sdk)\n",
            "  Downloading aioresponses-0.7.6-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: py-cpuinfo>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from inference-sdk) (9.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.9.0->inference-sdk) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.9.0->inference-sdk) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.9.0->inference-sdk) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.9.0->inference-sdk) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.9.0->inference-sdk) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.9.0->inference-sdk) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json>=0.6.0->inference-sdk)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json>=0.6.0->inference-sdk)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->inference-sdk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->inference-sdk) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->inference-sdk) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->inference-sdk) (2024.2.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision<1.0.0->inference-sdk) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision<1.0.0->inference-sdk) (3.7.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision<1.0.0->inference-sdk) (4.9.0.80)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision<1.0.0->inference-sdk) (6.0.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision<1.0.0->inference-sdk) (1.11.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.6.0->inference-sdk) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision<1.0.0->inference-sdk) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision<1.0.0->inference-sdk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision<1.0.0->inference-sdk) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision<1.0.0->inference-sdk) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision<1.0.0->inference-sdk) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision<1.0.0->inference-sdk) (2.8.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.6.0->inference-sdk)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.6.0->inference-sdk) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision<1.0.0->inference-sdk) (1.16.0)\n",
            "Installing collected packages: mypy-extensions, marshmallow, backoff, typing-inspect, supervision, dataclasses-json, aioresponses, inference-sdk\n",
            "Successfully installed aioresponses-0.7.6 backoff-2.2.1 dataclasses-json-0.6.4 inference-sdk-0.9.17 marshmallow-3.21.1 mypy-extensions-1.0.0 supervision-0.19.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install inference-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO2dJ31-v4az",
        "outputId": "b26ce3c9-6cd7-4dc2-8141-e692c329982f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/detection-of-motorcyclists-without-helmet/HelmetDetection/models/research/slim')\n",
        "!pip install tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DvKZZ-evrHZ",
        "outputId": "afbc5a35-6969-4ec8-ed45-6dfffae36c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/detection-of-motorcyclists-without-helmet/HelmetDetection/models/research\n"
          ]
        }
      ],
      "source": [
        "%cd /content/detection-of-motorcyclists-without-helmet/HelmetDetection/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ozRSk4-Mt5Oh"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "from google.colab.patches import cv2_imshow\n",
        "from inference_sdk import InferenceHTTPClient\n",
        "from PIL import Image\n",
        "# Import utilites\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ODMSeymU7jnL",
        "outputId": "92a4fa41-f691-44c2-cd45-cd419c93d6b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/detection-of-motorcyclists-without-helmet/HelmetDetection/models/research'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra_zb3-p--hA"
      },
      "source": [
        "# **Configure the paths to trained models**\n",
        "A Faster RCNN model is trained to detect motorcyclists in a given image.\n",
        "\n",
        "A YOLO model is trained to detect helmet in the given image of motorcyclist.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZwmRo4QJFE7V"
      },
      "outputs": [],
      "source": [
        "CWD_PATH = '/content/detection-of-motorcyclists-without-helmet/HelmetDetection/'\n",
        "\n",
        "MODEL_RCNN = 'rcnn'\n",
        "\n",
        "MODEL_YOLO='yolo'\n",
        "\n",
        "# Path to frozen detection graph .pb file, which contains the model that is used\n",
        "# for rcnn object detection.\n",
        "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_RCNN,'frozen_inference_graph.pb')\n",
        "\n",
        "# Path to label map file\n",
        "PATH_TO_LABELS = os.path.join(CWD_PATH,MODEL_RCNN,'label_map.pbtxt')\n",
        "\n",
        "# Path to yolo files\n",
        "configPath=os.path.join(CWD_PATH,MODEL_YOLO,'yolov3_custom.cfg')\n",
        "weightsPath=os.path.join(CWD_PATH,MODEL_YOLO,'yolov3_custom_4000.weights')\n",
        "labelsPath=os.path.join(CWD_PATH,MODEL_YOLO,'obj.names')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WV7pc28FYzP"
      },
      "source": [
        "# **Configure the input and output paths**\n",
        "\n",
        "Images of Motorcyclists without helmet are stored in the Output folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "scoBh0iIyS4h"
      },
      "outputs": [],
      "source": [
        "# Path to input image\n",
        "IMAGE_NAME = 'input/images/sample.jpeg'\n",
        "\n",
        "# Path to input video\n",
        "VIDEO_NAME = 'input/videos/clip.mp4'\n",
        "\n",
        "OUTPUT_FOLDER='output/'\n",
        "\n",
        "# Path to output\n",
        "PATH_TO_OUTPUT = os.path.join(CWD_PATH, OUTPUT_FOLDER,'/images')\n",
        "VIDEO_OUTPUT = os.path.join(CWD_PATH, OUTPUT_FOLDER,'output_clip.mp4')\n",
        "PATH_TO_IMAGE = os.path.join(CWD_PATH,IMAGE_NAME)\n",
        "NUMBER_PLATE_IMG_FOLDER = 'Number_plate_img/'\n",
        "PATH_TO_NUMBER_PLATE_IMG_FOLDER = os.path.join(CWD_PATH, NUMBER_PLATE_IMG_FOLDER)\n",
        "# Path to video\n",
        "PATH_TO_VIDEO = os.path.join(CWD_PATH,VIDEO_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft467aHO_Vs3"
      },
      "source": [
        "# **Configure Faster RCNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dAlwI92lxwaQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the label map.\n",
        "# Label maps map indices to category names\n",
        "# Here we use internal utility functions\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=1, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Load the Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.compat.v1.GraphDef()\n",
        "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "    sess = tf.compat.v1.Session(graph=detection_graph)\n",
        "\n",
        "# Define input and output tensors (i.e. data) for the object detection classifier\n",
        "\n",
        "# Input tensor is the image\n",
        "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "# Output tensors are the detection boxes, scores, and classes\n",
        "# Each box represents a part of the image where a particular object was detected\n",
        "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "# Each score represents level of confidence for each of the objects.\n",
        "# The score is shown on the result image, together with the class label.\n",
        "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "# Number of objects detected\n",
        "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlNGnJzEwm5S",
        "outputId": "964dfc6a-fd19-424e-8545-fd6a7218622f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 1, 'name': 'bikerider'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRfKWMum_gx5"
      },
      "source": [
        "# **Configure YOLO Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZOgzKRgUkwpr"
      },
      "outputs": [],
      "source": [
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "ln = net.getLayerNames()\n",
        "\n",
        "# Get the indices of the output layers\n",
        "output_layer_indices = net.getUnconnectedOutLayers()\n",
        "\n",
        "# Ensure output_layer_indices is in the correct format\n",
        "if not isinstance(output_layer_indices[0], list):\n",
        "    output_layer_indices = [output_layer_indices]\n",
        "\n",
        "# Retrieve the names of the output layers using the indices\n",
        "ln = [ln[i[0] - 1] for i in output_layer_indices]\n",
        "LABELS = open(labelsPath).read().strip().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzRktx_Gw2UP",
        "outputId": "b38b1a93-2778-448b-bb3a-5f9298d7b82a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Helmet', 'No Helmet']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "LABELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5GmKj5d_mdl"
      },
      "source": [
        "# **Detection Of Motorcyclists Without Helmet From Input Image**\n",
        "The two models are integrated to detect the motorcyclists without helmet from the input image and the images of riders without helmet are stored in the output folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EVQs0OyuyCO",
        "outputId": "7f77d9df-058a-4df8-8fd6-4f40021db2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"
          ]
        }
      ],
      "source": [
        "pip install imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Effi4loDu0Bq",
        "outputId": "1b212dfb-d9e7-4bbf-a842-51c623d048bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B3SEpWqAq5W"
      },
      "source": [
        "# **Detection Of Motorcyclists Without Helmet From Input Video Stream**\n",
        "The two models are integrated to detect the motorcyclists without helmet from the input video stream and the images of riders without helmet are stored in the output folder, along with the resulting video stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4994DAhCzkb",
        "outputId": "e0510dec-9115-45f2-8758-8658eaf1f96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-ocr\n",
            "  Downloading keras_ocr-0.9.3-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m973.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.6.2)\n",
            "Collecting efficientnet==1.0.0 (from keras-ocr)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting essential_generators (from keras-ocr)\n",
            "  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.50.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.4.0)\n",
            "Collecting pyclipper (from keras-ocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.66.2)\n",
            "Collecting validators (from keras-ocr)\n",
            "  Downloading validators-0.23.2-py3-none-any.whl (27 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet==1.0.0->keras-ocr)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (2.31.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.2)\n",
            "Installing collected packages: pyclipper, essential_generators, validators, keras-applications, efficientnet, keras-ocr\n",
            "Successfully installed efficientnet-1.0.0 essential_generators-1.0 keras-applications-1.0.8 keras-ocr-0.9.3 pyclipper-1.3.0.post5 validators-0.23.2\n"
          ]
        }
      ],
      "source": [
        "pip install keras-ocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def slow_down_video(input_video_path, output_video_path, slow_factor):\n",
        "    # Open the input video file\n",
        "    video_capture = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    output_video = cv2.VideoWriter(output_video_path, fourcc, fps / slow_factor, (frame_width, frame_height))\n",
        "\n",
        "    # Read and write frames\n",
        "    while True:\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Write each frame 'slow_factor' times\n",
        "        for _ in range(slow_factor):\n",
        "            output_video.write(frame)\n",
        "\n",
        "    # Release video capture and writer\n",
        "    video_capture.release()\n",
        "    output_video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Example usage:\n",
        "input_video_path = '/content/Swathi.mp4'\n",
        "output_video_path = '/content/Swathi_slowed.mp4'\n",
        "slow_factor = 2  # The factor by which to slow down the video\n",
        "slow_down_video(input_video_path, output_video_path, slow_factor)"
      ],
      "metadata": {
        "id": "5HBGun4RZWln"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6141ppv04fTR"
      },
      "outputs": [],
      "source": [
        "import imutils\n",
        "import shutil\n",
        "from inference_sdk import InferenceHTTPClient\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import platform  # Import the platform module\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_ocr\n",
        "import numpy as np\n",
        "#video = cv2.VideoCapture(\"PATH_TO_VIDEO\")\n",
        "video_name = '/content/video4.mp4'\n",
        "video = cv2.VideoCapture('/content/video4.mp4')\n",
        "CLIENT = InferenceHTTPClient(\n",
        "    api_url=\"https://detect.roboflow.com\",\n",
        "    api_key=\"FjebqrmWpFtuakWjQmwC\"\n",
        ")\n",
        "\n",
        "images=[]\n",
        "f=0\n",
        "size = (0, 0)\n",
        "j = 0\n",
        "while(video.isOpened()):\n",
        "  if f%3!=0:\n",
        "    ret,image = video.read()\n",
        "    f+=1\n",
        "    continue\n",
        "  ret,image = video.read()\n",
        "  if ret == True:\n",
        "    image=cv2.resize(image,None,fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
        "    image_expanded = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Perform the actual detection by running the model with the image as input\n",
        "    (boxes, scores, classes, num) = sess.run(\n",
        "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "        feed_dict={image_tensor: image_expanded})\n",
        "\n",
        "\n",
        "    #getting the normalized coordinates of boxes\n",
        "    normalizedBoxes = np.squeeze(boxes)\n",
        "    normalizedScores = np.squeeze(scores)\n",
        "    normalizedClasses = np.squeeze(classes)\n",
        "\n",
        "    #set a min thresh score, say 0.8\n",
        "    min_score_thresh = 0.8\n",
        "    detectedBoxes = normalizedBoxes[normalizedScores > min_score_thresh]\n",
        "    detectedClasses= normalizedClasses[normalizedScores > min_score_thresh]\n",
        "\n",
        "    #get image size\n",
        "    im_height,im_width, _=image.shape\n",
        "    size=(im_width, im_height)\n",
        "\n",
        "    #get coordinates of bike riders in image\n",
        "    final_boxes = []\n",
        "    for i in range(len(detectedBoxes)):\n",
        "        ymin, xmin, ymax, xmax = detectedBoxes[i]\n",
        "        final_boxes.append([xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height])\n",
        "\n",
        "    j=0\n",
        "    for [left,right,top,bottom] in final_boxes:\n",
        "        l=int(round(left))\n",
        "        r=int(round(right))\n",
        "        t=int(round(top))\n",
        "        b=int(round(bottom))\n",
        "        croppedImage=image[t:b,l:r]  # Extract each bike rider\n",
        "\n",
        "        cv2.rectangle(image, (l,t), (r,b), (255,0,0), 2)\n",
        "\n",
        "        # perform padding to cropped image\n",
        "        rows = croppedImage.shape[0]\n",
        "        cols = croppedImage.shape[1]\n",
        "        padding=0\n",
        "        if rows > cols:\n",
        "            padding = int((rows-cols) / 2)\n",
        "            paddedImg=cv2.copyMakeBorder(croppedImage, 0,0,padding, padding,  cv2.BORDER_CONSTANT, (0, 0, 0))\n",
        "        else:\n",
        "            paddedImg=croppedImage\n",
        "\n",
        "        # image preprocessing for yolo model\n",
        "        (H, W) = paddedImg.shape[:2]\n",
        "        blob = cv2.dnn.blobFromImage(paddedImg, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "\n",
        "        # run yolo model\n",
        "        net.setInput(blob)\n",
        "        layerOutputs = net.forward(ln)\n",
        "\n",
        "        # Initializing for getting box coordinates, confidences, classid\n",
        "        boxesH = []\n",
        "        confidencesH = []\n",
        "        classIDsH = []\n",
        "        thresholdH = 0.15\n",
        "\n",
        "        # getting coordinates of output predictions and performing NMS\n",
        "        for output in layerOutputs:\n",
        "            for detection in output:\n",
        "                confidenceOfEachClass = detection[5:]\n",
        "                classIDH = np.argmax(confidenceOfEachClass)    # get class with max confidence\n",
        "                confidenceH = confidenceOfEachClass[classIDH]  # get the max confidence\n",
        "                if confidenceH > thresholdH:\n",
        "                    boxH = detection[0:4] * np.array([W, H, W, H])\n",
        "                    (centerX, centerY, widthH, heightH) = boxH.astype(\"int\")\n",
        "                    x = int(centerX - (widthH / 2))\n",
        "                    y = int(centerY - (heightH / 2))\n",
        "                    boxesH.append([x, y, int(widthH), int(heightH)])\n",
        "                    confidencesH.append(float(confidenceH))\n",
        "                    classIDsH.append(classIDH)\n",
        "        idxs = cv2.dnn.NMSBoxes(boxesH, confidencesH, thresholdH, 0.1)\n",
        "\n",
        "        # bounding boxes for helmet- no helmet\n",
        "        if len(idxs) > 0:\n",
        "            for i in idxs.flatten():\n",
        "                (x, y) = (boxesH[i][0], boxesH[i][1])\n",
        "                (w, h) = (boxesH[i][2], boxesH[i][3])\n",
        "                if LABELS[classIDsH[i]] == 'Helmet':\n",
        "                    color = (0, 255, 0)\n",
        "                    cv2.rectangle(image, (x-padding, y), (x + w-padding, y + h), color, 2)\n",
        "                    text = \"{}\".format(LABELS[classIDsH[i]])\n",
        "                    cv2.putText(image, text, (x//2, y+ 4*h//3),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)\n",
        "                if (LABELS[classIDsH[i]] == 'No Helmet'):\n",
        "                    #store images with no helmet\n",
        "                    name=VIDEO_NAME.split(\".\")[0].split('/')[-1]+\"_\"+str(f)+\"_\"\n",
        "                    j+=1\n",
        "                    cv2.imwrite(PATH_TO_OUTPUT + '{}.jpg'.format(name+str(j)),croppedImage)\n",
        "                    # draw bounding boxes\n",
        "                    color = (0, 0, 255)\n",
        "                    cv2.rectangle(image, (x-padding, y), (x + w-padding, y + h), color, 2)\n",
        "                    text = \"{}\".format(LABELS[classIDsH[i]])\n",
        "                    cv2.putText(image, text, (x//2, y + 4* h//3),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)\n",
        "                    #Extract Number Plate\n",
        "                    result = CLIENT.infer(croppedImage, model_id=\"vehicle-registration-plates-trudk/2\")\n",
        "                    # Check if the result contains predictions\n",
        "                    if len(result['predictions']) > 0:\n",
        "                      cv2_imshow(croppedImage)\n",
        "                      predictions = result['predictions']\n",
        "                      image = croppedImage\n",
        "                      # Draw bounding boxes on the image\n",
        "                      for prediction in predictions:\n",
        "                          class_name = prediction.get('class')\n",
        "                          confidence = prediction.get('confidence')\n",
        "                          x, y, width, height = prediction.get('x'), prediction.get('y'), prediction.get('width'), prediction.get('height')\n",
        "\n",
        "                          # Convert coordinates to integers\n",
        "                          x, y, width, height = int(x), int(y), int(width), int(height)\n",
        "                          xmax, ymax = int(x + width), int(y + height)\n",
        "                          xmin, xmax, ymin, ymax = x - (width//2), x + (width//2), y - (width//2), y + (width//2)\n",
        "                          # Draw bounding box\n",
        "                          cv2.rectangle(croppedImage, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "                          #cv2.putText(croppedImage, f'{class_name} {confidence:.2f}', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "                          number_plate = croppedImage[ymin:ymax, xmin: xmax]\n",
        "                      # Show the image with bounding boxes\n",
        "                      cv2_imshow(image)\n",
        "                      cv2_imshow(number_plate)\n",
        "                      pipeline = keras_ocr.pipeline.Pipeline()\n",
        "\n",
        "                      # Path to your image file\n",
        "                      #image_path = '<path_to_image_file>'\n",
        "\n",
        "                      # Read the image\n",
        "                      images = [keras_ocr.tools.read(number_plate)]\n",
        "\n",
        "                      # Perform OCR on the image\n",
        "                      prediction_groups = pipeline.recognize(images)\n",
        "\n",
        "                      # Extract characters from the predictions\n",
        "                      license_plate = \"\"\n",
        "                      for image, predictions in zip(images, prediction_groups):\n",
        "                          for text, box in predictions:\n",
        "                              # Extracted character\n",
        "                              character = text\n",
        "                              # Bounding box coordinates\n",
        "                              x_min, y_min, x_max, y_max = box\n",
        "                              # Optionally, you can draw bounding boxes on the image\n",
        "                              keras_ocr.tools.drawAnnotations(image=image, predictions=[(text, box)])\n",
        "                              # Print the extracted character\n",
        "                              print(\"Character:\", character)\n",
        "                              license_plate += character\n",
        "\n",
        "                      # Show the image with bounding boxes (optional)\n",
        "                      plt.imshow(images[0])\n",
        "                      plt.axis('off')\n",
        "                      plt.show()\n",
        "                      print(license_plate)\n",
        "\n",
        "                    else:\n",
        "                      print(\"Number plate not found\")\n",
        "        images.append(image)\n",
        "    f+=1\n",
        "    #cv2_imshow(image)\n",
        "  else:\n",
        "    break\n",
        "video.release()\n",
        "\n",
        "out = cv2.VideoWriter(VIDEO_OUTPUT,cv2.VideoWriter_fourcc(*'mp4v'), 15, size)\n",
        "for i in range(len(images)):\n",
        "    out.write(images[i])\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}